import requests
import time
import sys,io
import csv
import random
from lxml import etree

#伪装浏览器
headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}
#代理ip网站
ip_url = 'http://www.xicidaili.com/nn/'
#获取ip数据
ip_data = requests.get(ip_url,headers=headers).text
#解析网页
r = etree.HTML(ip_data)
#lxml获取相对应的xpath
ip = r.xpath('//*[@id="ip_list"]/tr/td[2]/text()')
			#//*[@id="ip_list"]/tbody/tr[4]/td[2]
#建立一个空ip列表用来存储获得的ip
ip_list=[]

#测试ip是否可用
for ips in ip:
	try:
		proxy = {'http':ips}
		#循环列表的ip信息，向百度请求响应
		text_url = 'https://www.baidu.com/'
		#响应时间timeout=1，即在1秒内，未送到响应就断开连接
		res = requests.get(url=text_url,proxies=proxy,headers=headers,timeout=1)
		#将可用ip添加到ip列表ips_list中
		ip_list.append(ips)
	except Exception as e:
		print(e)
#在ip列表中随机选择ip
proxies = {'http':random.choice(ip_list)}
##将文件写入桌面文件doubanMovie中
with open(r'C:/Users/AOAO/Desktop/dy2018.csv','w',encoding='gb18030') as f:
	#写入csv文件
	writer = csv.writer(f)
	#第一行内容
	writer.writerow(('标题','日期','详情'))
	for i in range(302):
		url = 'https://www.dy2018.com/html/gndy/dyzz/index_{}.html'.format(i*25)
		data = requests.get(url,headers=headers,proxies=proxies).text
		s = etree.HTML(data)
		movie = s.xpath('//*[@id="header"]/div/div[3]/div[6]/div[2]/div[2]')
		time.sleep(1)
		for div in movie:
			name = div.xpath('./div[2]/ul/table/tr[2]/td[2]/b/a/text()')
			score = div.xpath('./div[2]/ul/table/tr[3]/td[2]/font/text()')
			scribe = div.xpath('./div[2]/ul/table/tr[4]/td[2]/font/text()')

			keyword = ['国产']
			if all(string not in name for string in keyword):
				f.write("{},{},{}\n".format(name,score,score))
